{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18fef4d",
   "metadata": {},
   "source": [
    "# Google Natural Language API test\n",
    "\n",
    "## 主要測試任務\n",
    "利用Google nlp API進行文本情感分析（`analyze_sentiment`）、實體辨識（`analyze_entities`）、句構分析（`analyze_syntax`）與文本分類（`classify_text`）測試 \n",
    "\n",
    "## 測試前準備\n",
    "1. 啟用Google Cloud Natural Language API （啟用教學可參考[此篇](https://segmentfault.com/a/1190000014216330)）\n",
    "2. Python >=3.6\n",
    "3. Google Cloud Natural Language API client Python library -> google-cloud-language\n",
    "\n",
    "## 測試步驟\n",
    "1. Set Up Authentication\n",
    "2. Test APIs\n",
    "\n",
    "\n",
    "## Reference \n",
    "皆參考[官方文件](https://cloud.google.com/natural-language/docs/reference/rpc/google.cloud.language.v1)與相關sample code，但官方文件可能許久未維護，有些範例程式並不可用，因此需稍加修改才能使用\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622107bd",
   "metadata": {},
   "source": [
    "## 1. Set Up Authentication\n",
    "[reference](https://stackoverflow.com/questions/44328277/how-to-auth-to-google-cloud-using-service-account-in-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382dfbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade google-cloud\n",
    "# !pip install --upgrade google-cloud-language\n",
    "\n",
    "import os\n",
    "from google.cloud import language_v1\n",
    "\n",
    "# setting the credentials locally \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'cred.json'\n",
    "\n",
    "# Instantiates a client\n",
    "client = language_v1.LanguageServiceClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16846d26",
   "metadata": {},
   "source": [
    "## 2. Test APIs\n",
    "> 官方的[試用api頁面](https://cloud.google.com/natural-language/)其實也不錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4bc1635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試用文字\n",
    "text = \"普通的版型沒有腰身，價錢便宜穿起來舒適！\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b5a9c",
   "metadata": {},
   "source": [
    "### 2.1 client.analyze_sentiment -> 做情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b2325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 普通的版型沒有腰身，價錢便宜穿起來舒適！\n",
      "Sentiment Score: 0.8999999761581421\n"
     ]
    }
   ],
   "source": [
    "# about sentiment score\n",
    "# https://cloud.google.com/natural-language/docs/reference/rpc/google.cloud.language.v1#google.cloud.language.v1.Sentiment\n",
    "\n",
    "def get_sentiment_score(content):\n",
    "\n",
    "    document = language_v1.Document(\n",
    "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "\n",
    "    # Detects the sentiment of the text\n",
    "    sentiment = client.analyze_sentiment(\n",
    "        request={\"document\": document}\n",
    "    ).document_sentiment\n",
    "    \n",
    "    score = sentiment.score\n",
    "    \n",
    "    return score\n",
    "\n",
    "sentiment = get_sentiment_score(text)\n",
    "\n",
    "print(\"Text: {}\".format(text))\n",
    "print(\"Sentiment Score: {}\".format(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f34879c",
   "metadata": {},
   "source": [
    "### 2.2 client.analyze_entities -> 做實體辨識"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f7f846c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 普通的版型沒有腰身，價錢便宜穿起來舒適！\n",
      "\n",
      "Representative name for the entity: 版型\n",
      "Entity type: OTHER\n",
      "Salience score: 0.38793444633483887\n",
      "Mention text: 版型\n",
      "Mention type: COMMON\n",
      "\n",
      "Representative name for the entity: 價錢\n",
      "Entity type: OTHER\n",
      "Salience score: 0.3216562867164612\n",
      "Mention text: 價錢\n",
      "Mention type: COMMON\n",
      "\n",
      "Representative name for the entity: 腰身\n",
      "Entity type: OTHER\n",
      "Salience score: 0.29040926694869995\n",
      "Mention text: 腰身\n",
      "Mention type: COMMON\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# about entities\n",
    "# https://cloud.google.com/natural-language/docs/reference/rpc/google.cloud.language.v1#google.cloud.language.v1.Entity\n",
    "\n",
    "def get_entities(content):\n",
    "\n",
    "    document = language_v1.Document(\n",
    "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "\n",
    "    # Detects the entities of the text\n",
    "    response = client.analyze_entities(\n",
    "        request={\"document\": document}\n",
    "    )\n",
    "    \n",
    "    print(\"Text: {}\".format(content))\n",
    "    print()\n",
    "    for entity in response.entities:\n",
    "        print(u\"Representative name for the entity: {}\".format(entity.name))\n",
    "\n",
    "        # Get entity type, e.g. PERSON, LOCATION, ADDRESS, NUMBER, et al\n",
    "        print(u\"Entity type: {}\".format(language_v1.Entity.Type(entity.type_).name))\n",
    "\n",
    "        # Get the salience score associated with the entity in the [0, 1.0] range\n",
    "        # salience score 某字對文本的重要性\n",
    "        print(u\"Salience score: {}\".format(entity.salience))\n",
    "\n",
    "        # Loop over the metadata associated with entity. For many known entities,\n",
    "        # the metadata is a Wikipedia URL (wikipedia_url) and Knowledge Graph MID (mid).\n",
    "        # Some entity types may have additional metadata, e.g. ADDRESS entities\n",
    "        # may have metadata for the address street_name, postal_code, et al.\n",
    "        for metadata_name, metadata_value in entity.metadata.items():\n",
    "            print(u\"{}: {}\".format(metadata_name, metadata_value))\n",
    "\n",
    "        # Loop over the mentions of this entity in the input document.\n",
    "        # The API currently supports proper noun mentions.\n",
    "        for mention in entity.mentions:\n",
    "            print(u\"Mention text: {}\".format(mention.text.content))\n",
    "\n",
    "            # Get the mention type, e.g. PROPER for proper noun\n",
    "            print(\n",
    "                u\"Mention type: {}\".format(language_v1.EntityMention.Type(mention.type_).name)\n",
    "            )\n",
    "        print()\n",
    "    return response\n",
    "\n",
    "entities = get_entities(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc21d55",
   "metadata": {},
   "source": [
    "### 2.3 client.analyze_syntax -> 做語句結構分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a0c0088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 普通的版型沒有腰身，價錢便宜穿起來舒適！\n",
      "\n",
      "Token text: 普通\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: ADJ\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 普通\n",
      "Head token index: 2\n",
      "Label: AMOD\n",
      "\n",
      "Token text: 的\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: PRT\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 的\n",
      "Head token index: 0\n",
      "Label: RCMODREL\n",
      "\n",
      "Token text: 版型\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: NOUN\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 版型\n",
      "Head token index: 3\n",
      "Label: NSUBJ\n",
      "\n",
      "Token text: 沒有\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: VERB\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 沒有\n",
      "Head token index: 8\n",
      "Label: DEP\n",
      "\n",
      "Token text: 腰身\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: NOUN\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 腰身\n",
      "Head token index: 3\n",
      "Label: DOBJ\n",
      "\n",
      "Token text: ，\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: PUNCT\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: ，\n",
      "Head token index: 8\n",
      "Label: P\n",
      "\n",
      "Token text: 價錢\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: NOUN\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 價錢\n",
      "Head token index: 8\n",
      "Label: NSUBJ\n",
      "\n",
      "Token text: 便宜\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: ADJ\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 便宜\n",
      "Head token index: 8\n",
      "Label: ADVMOD\n",
      "\n",
      "Token text: 穿\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: VERB\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 穿\n",
      "Head token index: 8\n",
      "Label: ROOT\n",
      "\n",
      "Token text: 起來\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: VERB\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 起來\n",
      "Head token index: 8\n",
      "Label: PRT\n",
      "\n",
      "Token text: 舒適\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: ADJ\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: 舒適\n",
      "Head token index: 8\n",
      "Label: ACOMP\n",
      "\n",
      "Token text: ！\n",
      "Location of this token in overall document: -1\n",
      "Part of Speech tag: PUNCT\n",
      "Voice: VOICE_UNKNOWN\n",
      "Tense: TENSE_UNKNOWN\n",
      "Lemma: ！\n",
      "Head token index: 8\n",
      "Label: P\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# about syntax\n",
    "# https://cloud.google.com/natural-language/docs/reference/rpc/google.cloud.language.v1#google.cloud.language.v1.Entity\n",
    "\n",
    "def get_syntax(content):\n",
    "\n",
    "    document = language_v1.Document(\n",
    "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "\n",
    "    # Detects the syntax of the text\n",
    "    response = client.analyze_syntax(\n",
    "        request={\"document\": document}\n",
    "    )\n",
    "    \n",
    "    print(\"Text: {}\".format(content))\n",
    "    print()\n",
    "    \n",
    "    tmp = []\n",
    "    for token in response.tokens:\n",
    "        # Get the text content of this token. Usually a word or punctuation.\n",
    "        text = token.text\n",
    "        print(u\"Token text: {}\".format(text.content))\n",
    "        print(\n",
    "            u\"Location of this token in overall document: {}\".format(text.begin_offset)\n",
    "        )\n",
    "        # Get the part of speech information for this token.\n",
    "        # Part of speech is defined in:\n",
    "        # http://www.lrec-conf.org/proceedings/lrec2012/pdf/274_Paper.pdf\n",
    "        part_of_speech = token.part_of_speech\n",
    "        # Get the tag, e.g. NOUN, ADJ for Adjective, et al.\n",
    "        print(\n",
    "            u\"Part of Speech tag: {}\".format(\n",
    "                language_v1.PartOfSpeech.Tag(part_of_speech.tag).name\n",
    "            )\n",
    "        )\n",
    "        # Get the voice, e.g. ACTIVE or PASSIVE\n",
    "        print(u\"Voice: {}\".format(language_v1.PartOfSpeech.Voice(part_of_speech.voice).name))\n",
    "        # Get the tense, e.g. PAST, FUTURE, PRESENT, et al.\n",
    "        print(u\"Tense: {}\".format(language_v1.PartOfSpeech.Tense(part_of_speech.tense).name))\n",
    "        # See API reference for additional Part of Speech information available\n",
    "        # Get the lemma of the token. Wikipedia lemma description\n",
    "        # https://en.wikipedia.org/wiki/Lemma_(morphology)\n",
    "        print(u\"Lemma: {}\".format(token.lemma))\n",
    "        # Get the dependency tree parse information for this token.\n",
    "        # For more information on dependency labels:\n",
    "        # http://www.aclweb.org/anthology/P13-2017\n",
    "        dependency_edge = token.dependency_edge\n",
    "        print(u\"Head token index: {}\".format(dependency_edge.head_token_index))\n",
    "        print(\n",
    "            u\"Label: {}\".format(language_v1.DependencyEdge.Label(dependency_edge.label).name)\n",
    "        )\n",
    "\n",
    "        print()\n",
    "        tmp.append([text.content, language_v1.PartOfSpeech.Tag(part_of_speech.tag).name,\n",
    "                    dependency_edge.head_token_index,\n",
    "                    language_v1.DependencyEdge.Label(dependency_edge.label).name])\n",
    "    return tmp\n",
    "\n",
    "syntax = get_syntax(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a216e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e3a44e0040bf4712bcd58f685d9e00b0-0\" class=\"displacy\" width=\"1010\" height=\"137.0\" direction=\"ltr\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">普通</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">的</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">PRT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">版型</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">沒有</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">腰身</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">，</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PUNCT</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">價錢</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">便宜</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">穿</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">起來</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">舒適</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">！</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">PUNCT</tspan>\n",
       "</text>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# !pip install --upgrade spacy\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "tokens = {\n",
    "    \"words\": [\n",
    "    ],\n",
    "    \"arcs\": [\n",
    "    ]\n",
    "}\n",
    "for i, item in enumerate(syntax):\n",
    "    tokens[\"words\"].append({\"text\": item[0], \"tag\": item[1]})\n",
    "    \n",
    "displacy.render(tokens, style='dep', jupyter=True,\n",
    "                manual=True, options={'distance': 80})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed8db02",
   "metadata": {},
   "source": [
    "### 2.4 client.classify_text -> 做文本分類\n",
    "> 但不支援中文（The language zh-Hant is not supported for classify_text analysis.）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e38364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: President Biden is giving a speech in Poland to wrap up a visit to Europe intended to bolster NATO’s unity over Russia’s invasion of Ukraine. While Mr. Biden was in Warsaw, an missile strike rocked the city of Lviv in western Ukraine, close to the Polish border.\n",
      "\n",
      "====================\n",
      "category        : /News/Politics\n",
      "confidence      : 0.8899999856948853\n",
      "====================\n",
      "category        : /Law & Government/Government\n",
      "confidence      : 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# about classify_text\n",
    "# https://cloud.google.com/natural-language/docs/samples/language-classify-text-tutorial-classify\n",
    "\n",
    "def classify_text(content, verbose=True):\n",
    "\n",
    "    document = language_v1.Document(\n",
    "        content=content, type_=language_v1.Document.Type.PLAIN_TEXT\n",
    "    )\n",
    "\n",
    "    response = client.classify_text(\n",
    "        request={\"document\": document}\n",
    "    )\n",
    "    \n",
    "    print(\"Text: {}\".format(content))\n",
    "    print()\n",
    "    \n",
    "    categories = response.categories\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    for category in categories:\n",
    "        # Turn the categories into a dictionary of the form:\n",
    "        # {category.name: category.confidence}, so that they can\n",
    "        # be treated as a sparse vector.\n",
    "        result[category.name] = category.confidence\n",
    "\n",
    "    if verbose:\n",
    "        for category in categories:\n",
    "            print(u\"=\" * 20)\n",
    "            print(u\"{:<16}: {}\".format(\"category\", category.name))\n",
    "            print(u\"{:<16}: {}\".format(\"confidence\", category.confidence))\n",
    "\n",
    "    return result\n",
    "\n",
    "text = \"President Biden is giving a speech in Poland to wrap up a visit to Europe intended to bolster NATO’s unity over Russia’s invasion of Ukraine. While Mr. Biden was in Warsaw, an missile strike rocked the city of Lviv in western Ukraine, close to the Polish border.\"\n",
    "classify_text = classify_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
